{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies the path to the chromedriver.exe\n",
    "driver = webdriver.Chrome('/Users/username/bin/chromedriver')\n",
    "\n",
    "# driver.get method() will navigate to a page given by the URL address\n",
    "driver.get('https://www.linkedin.com/uas/login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('config.txt')\n",
    "lines = file.readlines()\n",
    "username = lines[0].strip('\\n')\n",
    "password = lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate email form by_id\n",
    "elementID = driver.find_element(By.ID, \"username\")\n",
    "elementID.send_keys(username)\n",
    "sleep(0.5)\n",
    "\n",
    "# locate password form by_id\n",
    "elementID = driver.find_element(By.ID, \"password\")\n",
    "elementID.send_keys(password)\n",
    "sleep(0.5)\n",
    "\n",
    "# .submit() to mimic button click\n",
    "elementID.submit()\n",
    "sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https:www.google.com')\n",
    "sleep(3)\n",
    "\n",
    "search_q = 'site:linkedin.com/in/ AND \"Biomedical Engineer\" AND \"Pakistan\"'\n",
    "\n",
    "search_query = driver.find_element(By.NAME, 'q')\n",
    "search_query.send_keys(search_q)\n",
    "sleep(0.5)\n",
    "\n",
    "search_query.send_keys(Keys.RETURN)\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = driver.find_elements(By.CSS_SELECTOR, \".NJo7tc.Z26q7c.UK95Uc.uUuwM.jGGQ5e [href]\")\n",
    "linkedin_urls = [elem.get_attribute('href') for elem in elems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "job_list = []\n",
    "company_list = []\n",
    "college_list = []\n",
    "location_list = []\n",
    "link_list = []\n",
    "twitter_list = []\n",
    "email_list = []\n",
    "contact_list = []\n",
    "address_list = []\n",
    "\n",
    "# For loop to iterate over each URL in the list\n",
    "for linkedin_url in linkedin_urls:\n",
    "    # get the profile URL \n",
    "    driver.get(linkedin_url)\n",
    "    # add a 5 second pause loading each URL\n",
    "    sleep(5)\n",
    "    # assigning the source code for the webpage to variable soup\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    info_div = soup.find('div', {'class': 'mt2 relative'})\n",
    "    \n",
    "    # extract the text from the class containing the name\n",
    "    name = info_div.find('h1', {'class': 'text-heading-xlarge inline t-24 v-align-middle break-words'})\n",
    "    if name:\n",
    "        name = name.get_text().strip()\n",
    "    name_list.append(name)\n",
    "    \n",
    "    # extract the text from the class containing the Job Title\n",
    "    job_title = info_div.find('div', {'class': 'text-body-medium break-words'})\n",
    "    if job_title:\n",
    "        job_title = job_title.get_text().strip()\n",
    "    job_list.append(job_title)\n",
    "    \n",
    "    # extract the text from the class containing the company\n",
    "    company = info_div.find('div', {'aria-label': 'Current company'})\n",
    "    if company:\n",
    "        company = company.get_text().strip()\n",
    "    company_list.append(company)\n",
    "    \n",
    "    # extract the text from the class containing the College\n",
    "    college = info_div.find('div', {'aria-label': 'Education'})\n",
    "    if college:\n",
    "        college = college.get_text().strip()\n",
    "    college_list.append(college)\n",
    "    \n",
    "    # extract the text from the class containing the location\n",
    "    location = info_div.find('span', {'class': 'text-body-small inline t-black--light break-words'})\n",
    "    if location:\n",
    "        location = location.get_text().strip()\n",
    "    location_list.append(location)\n",
    "    \n",
    "    contact_info = driver.find_element(By.ID, 'top-card-text-details-contact-info')\n",
    "    contact_info.send_keys(Keys.RETURN)\n",
    "    sleep(3)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    contact_div = soup.find('div', {'class': 'artdeco-modal__content ember-view'})\n",
    "    \n",
    "    # extract the text from the class containing the linkedIn Profile\n",
    "    profile = contact_div.find('section', {'class': 'pv-contact-info__contact-type ci-vanity-url'})\n",
    "    if profile:\n",
    "        profile = profile.find('div', {'class': 'pv-contact-info__ci-container t-14'})\n",
    "        profile = profile.get_text().strip()\n",
    "    link_list.append(profile)\n",
    "    \n",
    "    \n",
    "    # extract the text from the class containing the Twitter\n",
    "    twitter = contact_div.find('section', {'class': 'pv-contact-info__contact-type ci-twitter'})\n",
    "    if twitter:\n",
    "        twitter = twitter.find('li', {'class': 'pv-contact-info__ci-container t-14'})\n",
    "        twitter = twitter.get_text().strip()\n",
    "    twitter_list.append(twitter)\n",
    "    \n",
    "    # extract the text from the class containing the Email Address\n",
    "    email = contact_div.find('section', {'class': 'pv-contact-info__contact-type ci-email'})\n",
    "    if email:\n",
    "        email = email.find('div', {'class': 'pv-contact-info__ci-container t-14'})\n",
    "        email = email.get_text().strip()\n",
    "    email_list.append(email)\n",
    "    \n",
    "    # extract the text from the class containing the Contact Number\n",
    "    contact = contact_div.find('section', {'class': 'pv-contact-info__contact-type ci-phone'})\n",
    "    if contact:\n",
    "        contact = contact.find('span', {'class': 't-14 t-black t-normal'})\n",
    "        contact = contact.get_text().strip()\n",
    "    contact_list.append(contact)\n",
    "    \n",
    "    # extract the text from the class containing the Address\n",
    "    address = contact_div.find('section', {'class': 'pv-contact-info__contact-type ci-address'})\n",
    "    if address:\n",
    "        address = address.find('div', {'class': 'pv-contact-info__ci-container t-14'})\n",
    "        address = address.get_text().strip()\n",
    "    address_list.append(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminates the application\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'NAME' : name_list, \n",
    "                   'JOB TITLE' : job_list, \n",
    "                   'COMPANY' : company_list, \n",
    "                   'COLLEGE' : college_list, \n",
    "                   'LOCATION' : location_list, \n",
    "                   'LINKEDIN' : link_list,\n",
    "                   'TWITTER' : twitter_list,\n",
    "                   'EMAIL' : email_list,\n",
    "                   'CONTACT' : contact_list,\n",
    "                   'ADDRESS' : address_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bioengineers.csv', index = False, encoding='utf-8') # False: not include index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
